use ReLU model
Network prediction: tensor([[2., 0.]], device='cuda:0', grad_fn=<AddmmBackward0>)
Verifiying Pertubation - 1
using beta-CROWN
using CROWN
result from crown is: tensor([[-1.]], device='cuda:0', grad_fn=<AddBackward0>)
using alpha-CROWN
ret: tensor([[-1.]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.7000]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.4060]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2940]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.3594]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.4032]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.4310]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.4463]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.4517]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.4490]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.4398]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.4251]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.4059]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.3829]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.3568]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.3280]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2971]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2643]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.3102]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.3491]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.3407]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2965]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2584]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2758]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2875]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2942]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2965]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2949]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2900]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2822]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2718]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2592]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2660]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2747]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2552]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2624]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2721]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2780]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2805]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2800]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2769]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2715]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2641]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2550]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2670]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2727]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2568]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2590]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2668]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2715]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2736]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2734]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2711]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2670]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2614]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2544]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2612]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2654]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2528]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2580]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2641]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2679]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2696]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2694]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2676]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2645]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2601]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2547]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2549]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2581]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2506]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2521]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2521]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2508]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2553]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2503]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2551]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2584]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2602]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2606]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2598]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2579]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2551]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2515]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2585]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2602]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2523]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2545]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2582]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2605]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2615]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2616]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2607]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2590]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2566]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2536]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2501]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2616]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2645]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[-0.2600]], device='cuda:0', grad_fn=<AddBackward0>)
result from alpha crown is: tensor([[-0.2501]], device='cuda:0', grad_fn=<MaximumBackward0>)
unstable: 2

instance 0 have not been verified with lb tensor([-0.2501], device='cuda:0', grad_fn=<SelectBackward0>) and C tensor([[[ 1., -1.]]], device='cuda:0')
C [(tensor([[ 0.,  0.],
        [ 0., -3.],
        [-3.,  0.],
        [-3., -3.]], device='cuda:0'), tensor([[3., 3.],
        [3., 0.],
        [0., 3.],
        [0., 0.]], device='cuda:0'))]
split: [tensor([[-1., -1.],
        [-1.,  1.],
        [ 1., -1.],
        [ 1.,  1.]], device='cuda:0')]
ret: tensor([[ 0., -1., -1.,  2.]], device='cuda:0', grad_fn=<AddBackward0>)
ret: tensor([[ 0.0500, -0.8500, -0.8500,  2.0000]], device='cuda:0',
       grad_fn=<AddBackward0>)
ret: tensor([[ 0.0990, -0.7030, -0.7030,  2.0000]], device='cuda:0',
       grad_fn=<AddBackward0>)
ret: tensor([[ 0.1470, -0.5589, -0.5589,  2.0000]], device='cuda:0',
       grad_fn=<AddBackward0>)
ret: tensor([[ 0.1941, -0.4178, -0.4178,  2.0000]], device='cuda:0',
       grad_fn=<AddBackward0>)
ret: tensor([[ 0.2402, -0.2794, -0.2794,  2.0000]], device='cuda:0',
       grad_fn=<AddBackward0>)
ret: tensor([[ 0.2854, -0.1438, -0.1438,  2.0000]], device='cuda:0',
       grad_fn=<AddBackward0>)
ret: tensor([[ 0.3297, -0.0109, -0.0109,  2.0000]], device='cuda:0',
       grad_fn=<AddBackward0>)
ret: tensor([[0.3731, 0.1193, 0.1193, 2.0000]], device='cuda:0',
       grad_fn=<AddBackward0>)
verified!!!!

all batches are verified!
